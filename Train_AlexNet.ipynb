{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np  \n",
    "np.set_printoptions(threshold=np.inf)\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,Dense,Flatten,Dropout,ZeroPadding2D,BatchNormalization,Activation,add,AveragePooling2D\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D  \n",
    "from keras.applications.imagenet_utils import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(image_name):\n",
    "    im=cv2.imread(image_name)\n",
    "    im=cv2.resize(im, (227, 227))\n",
    "    return im\n",
    "\n",
    "#数据扩充\n",
    "def img_Rotation(img,angel):\n",
    "    if(0 == angel):\n",
    "        dst = img\n",
    "    else:\n",
    "        rows,cols=img.shape[:2]\n",
    "        #angel度旋转\n",
    "        M=cv2.getRotationMatrix2D((cols/2,rows/2),angel,1)\n",
    "        dst=cv2.warpAffine(img,M,(cols,rows))\n",
    "    \n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-05 19:14:25Get 128000 Train Images\n",
      "2020-02-05 19:14:25np.array\n",
      "2020-02-05 20:10:59preprocess\n",
      "2020-02-05 23:34:39Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = 'AID'\n",
    "Extension='.jpg'\n",
    "ModelName = \"AlexNet\"\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "base_path='./Dataset/' + dataset\n",
    "\n",
    "All_Labels = os.listdir(os.path.join(base_path, 'Train'))\n",
    "num_classes = len(All_Labels)\n",
    "images_Train = []\n",
    "labels_Train = []\n",
    "images_Val = []\n",
    "labels_Val = []\n",
    "\n",
    "for i in range(0, num_classes):\n",
    "    file_dir = os.path.join(base_path, 'Train', All_Labels[i])\n",
    "    file_names = os.listdir(file_dir)\n",
    "    for file_name in file_names:\n",
    "        if(file_name.endswith(Extension)):\n",
    "            finalFileName = os.path.join(file_dir, file_name)\n",
    "            Label = np.linspace(0, 0, num_classes, dtype='int32')\n",
    "            Label[i] = 1\n",
    "            original_img = read_image(finalFileName)\n",
    "            flipped_img = cv2.flip(original_img, 0)\n",
    "            \n",
    "            for j in [0, 45, 90, 135, 180, 225, 270, 315]: \n",
    "                images_Train.append(img_Rotation(original_img, j))\n",
    "                labels_Train.append(Label)               \n",
    "                images_Train.append(img_Rotation(flipped_img, j))\n",
    "                labels_Train.append(Label)\n",
    "                \n",
    "print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) + \"Get %d Train Images\" %(len(images_Train)))\n",
    "\n",
    "print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) + \"np.array\")\n",
    "X_Train = np.array(images_Train, dtype='float32')\n",
    "Y_Train = np.array(labels_Train)\n",
    "del images_Train\n",
    "gc.collect()\n",
    "\n",
    "print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) + \"preprocess\")\n",
    "X_Train = preprocess_input(X_Train)\n",
    "gc.collect()\n",
    "print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) + \"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD  \n",
    "def AlexNet(shape):\n",
    "    inpt = Input(shape=shape)  \n",
    "    x = Conv2D(96,(11,11),strides=(4,4),padding='valid',activation='relu',kernel_initializer='uniform')(inpt)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(3,3),strides=(2,2))(x)\n",
    "    x = Conv2D(256,(5,5),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform')(x) \n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(3,3),strides=(2,2))(x)\n",
    "    x = Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform')(x) \n",
    "    x = BatchNormalization()(x) \n",
    "    x = Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform')(x) \n",
    "    x = BatchNormalization()(x) \n",
    "    x = Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform')(x) \n",
    "    x = BatchNormalization()(x) \n",
    "    x = MaxPooling2D(pool_size=(3,3),strides=(2,2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(4096,activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(4096,activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(num_classes,activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inpt,outputs=x, name=ModelName)  \n",
    "    sgd = SGD(decay=0.0001,momentum=0.9)  \n",
    "    model.compile(loss='categorical_crossentropy',optimizer=\"SGD\",metrics=['accuracy']) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"AlexNet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 227, 227, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 55, 55, 96)        34944     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 55, 55, 96)        384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 27, 27, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 27, 27, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 13, 13, 384)       885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 13, 13, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 13, 13, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 13, 13, 256)       884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              37752832  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 30)                122910    \n",
      "=================================================================\n",
      "Total params: 58,409,758\n",
      "Trainable params: 58,407,006\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = AlexNet(X_Train.shape[1:])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "128000/128000 [==============================] - 4772s 37ms/step - loss: 0.0252 - accuracy: 0.9915\n",
      "Epoch 2/10\n",
      "128000/128000 [==============================] - 5997s 47ms/step - loss: 0.0224 - accuracy: 0.9925\n",
      "Epoch 3/10\n",
      "128000/128000 [==============================] - 5994s 47ms/step - loss: 0.0218 - accuracy: 0.9927\n",
      "Epoch 4/10\n",
      "128000/128000 [==============================] - 5934s 46ms/step - loss: 0.0215 - accuracy: 0.9929\n",
      "Epoch 5/10\n",
      "128000/128000 [==============================] - 9143s 71ms/step - loss: 0.0216 - accuracy: 0.9926\n",
      "Epoch 6/10\n",
      "128000/128000 [==============================] - 6969s 54ms/step - loss: 0.0168 - accuracy: 0.9944\n",
      "Epoch 7/10\n",
      "128000/128000 [==============================] - 6538s 51ms/step - loss: 0.0174 - accuracy: 0.9940\n",
      "Epoch 8/10\n",
      "128000/128000 [==============================] - 6373s 50ms/step - loss: 0.0172 - accuracy: 0.9943\n",
      "Epoch 9/10\n",
      "128000/128000 [==============================] - 6447s 50ms/step - loss: 0.0164 - accuracy: 0.9946\n",
      "Epoch 10/10\n",
      "128000/128000 [==============================] - 8000s 62ms/step - loss: 0.0174 - accuracy: 0.9942\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_Train, Y_Train, batch_size=batch_size, epochs=epochs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-09 08:59:34Saved Model to disk\n"
     ]
    }
   ],
   "source": [
    "save_folder = 'models/' + time.strftime(\"%Y-%m-%d\", time.localtime()) + '/' + dataset\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "# serialize model to JSON\n",
    "import pickle\n",
    "model_json = model.to_json()\n",
    "with open(os.path.join(save_folder, ModelName + \".json\"), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save(os.path.join(save_folder, ModelName + \".h5\"))\n",
    "#pickle.dump(history.history, open('history/UCMerced_LandUse/AlexNet.p','wb'))\n",
    "print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) + \"Saved Model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
